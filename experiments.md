# Эксперименты

### Анализ энкодеров

| Модель      | Параметры | VRAM (инференс) | VRAM (обучение FP32) | VRAM (обучение FP16) |
|------------|-----------|-----------------|----------------------|----------------------|
| **ViT-B/16**   | 86M       | 1.5–2 ГБ        | 6–8 ГБ               | 4–5 ГБ               |
| **ViT-S/16**   | 22M       | ~1 ГБ           | 3–4 ГБ               | 2–3 ГБ               |
| **ResNet-50**  | 25.6M     | ~1 ГБ           | 4–5 ГБ               | 2–3 ГБ               |
| **MAE (ViT-B)** | 86M      | 1.5–2 ГБ        | 6–8 ГБ               | 4–5 ГБ               |
| **BEiT-B/16**   | 86M      | 1.5–2 ГБ        | 6–8 ГБ               | 4–5 ГБ               |

### Эксперименты
1. Мы написали свой семплинг на пары изображений и преобразовали таким образом датасет, и обучали Siamese модель на схожесть изображений, но этот подход по понятным причинам отказался не лучше чем разбиение на тройки `triplet: (anchor, positive, negative)`, но это разбиение понадобилось нам на создание **валидационной выборки** как в test_public.
2. Пробовали использовать не только **Triplet loss**, но и другие лоссы, такие как **ArcFace** и **CosFace**, но это не дало прироста, а только ухучшило показатели по сравнению с Triplet loss
3. В Конечной версии, мы реализовали двух этапное обучение, с разными подходами к семплинг, которое выдало лучший score
    - в первом этапе модель генерализует информацию о людях, обучается их различать
    - во втором этапе модель вытаскивает сложные примеры из датасета, и с меньшим шагом обучения дообучается на сложных примерах
